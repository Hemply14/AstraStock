import yfinance as yf
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split, TimeSeriesSplit, RandomizedSearchCV
from sklearn.linear_model import LinearRegression
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
from sklearn.preprocessing import StandardScaler
import xgboost as xgb
import lightgbm as lgb
import shap
import streamlit as st
import plotly.graph_objects as go
import plotly.express as px
from plotly.subplots import make_subplots
import warnings
import time
from concurrent.futures import ThreadPoolExecutor, as_completed
from functools import lru_cache
import joblib
import json
from typing import Dict, List, Tuple, Optional
from scipy import stats
warnings.filterwarnings('ignore')

class EnhancedStockPredictor:
    def __init__(self, symbol: str, period: str = "5y", lookback_days: int = 20):
        """
        Enhanced Stock Predictor with hyperparameter tuning, backtesting, and stacking ensemble
        
        Parameters:
        symbol (str): Stock symbol (e.g., 'TCS.NS', 'RELIANCE.NS')
        period (str): Period for historical data ('1y', '2y', '5y', etc.)
        lookback_days (int): Number of days for lookback features
        """
        self.symbol = symbol.upper()
        self.period = period
        self.lookback_days = lookback_days
        self.max_position_pct = 0.30     # Max 30% capital per trade
        self.stop_loss_pct = 0.02        # 2% stop loss
        self.take_profit_pct = 0.02      # 2% take profit
        self.min_cash_reserve = 0.20     # Keep 20% cash
        self.data = None
        self.features = None
        self.target = None
        self.models = {}
        self.scaler = StandardScaler()
        self.feature_names = []
        self.shap_explainers = {}
        self.walk_forward_results = {}
        self.ensemble_weights = {}
        self.prediction_intervals = {}
        self.best_params = {}
        self.backtest_results = {}
        self.stacking_model = None
        self.meta_features = None
        
    def fetch_data(self) -> bool:
        """Fetch historical stock data from Yahoo Finance"""
        try:
            print(f"üìä Fetching data for {self.symbol}...")
            ticker = yf.Ticker(self.symbol)
            self.data = ticker.history(period=self.period)
            
            if self.data.empty:
                raise ValueError(f"No data found for symbol {self.symbol}")
            
            # Validate data quality
            if not self._validate_data_quality():
                return False
                
            print(f"‚úÖ Successfully fetched {len(self.data)} days of data")
            return True
            
        except Exception as e:
            print(f"‚ùå Error fetching data: {e}")
            return False
    
    def _validate_data_quality(self) -> bool:
        """Validate data quality and handle issues"""
        if self.data is None:
            return False
            
        # Check for missing values
        missing_pct = self.data.isnull().sum() / len(self.data)
        high_missing = missing_pct[missing_pct > 0.1]
        if not high_missing.empty:
            print(f"‚ö†Ô∏è High missing values in: {high_missing.index.tolist()}")
            
        # Check for constant columns
        constant_cols = [col for col in self.data.columns if self.data[col].nunique() <= 1]
        if constant_cols:
            print(f"‚ö†Ô∏è Constant columns: {constant_cols}")
            
        # Check for low volume days
        volume_threshold = self.data['Volume'].quantile(0.1)
        low_volume_days = self.data[self.data['Volume'] < volume_threshold]
        if len(low_volume_days) > len(self.data) * 0.1:
            print(f"‚ö†Ô∏è {len(low_volume_days)} low volume days detected")
            
        return True
    
    def create_corrected_features(self) -> bool:
        """
        Create features with proper time series structure
        CRITICAL FIX: Target is next day's closing price with proper shifting
        """
        if self.data is None:
            print("No data available. Please fetch data first.")
            return False
            
        df = self.data.copy()
        
        print("üîÑ Creating features with proper time series structure...")
        
        # BASIC PRICE FEATURES (all lagged by 1 day to prevent data leakage)
        df['Returns'] = df['Close'].pct_change().shift(1)
        df['Log_Returns'] = np.log(df['Close'] / df['Close'].shift(1)).shift(1)
        df['High_Low_Pct'] = ((df['High'] - df['Low']) / df['Close']).shift(1)
        df['Open_Close_Pct'] = ((df['Close'] - df['Open']) / df['Open']).shift(1)
        
        # VOLUME FEATURES (lagged)
        df['Volume_MA'] = df['Volume'].rolling(window=10).mean().shift(1)
        df['Volume_Ratio'] = (df['Volume'] / df['Volume_MA']).shift(1)
        df['Price_Volume'] = (df['Close'] * df['Volume']).shift(1)
        
        # TECHNICAL INDICATORS (all properly lagged)
        for window in [5, 10, 20, 50]:
            df[f'SMA_{window}'] = df['Close'].rolling(window=window).mean().shift(1)
            df[f'Close_SMA_{window}_Ratio'] = (df['Close'] / df[f'SMA_{window}']).shift(1)
        
        # EXPONENTIAL MOVING AVERAGES (lagged)
        for span in [12, 26, 50]:
            df[f'EMA_{span}'] = df['Close'].ewm(span=span).mean().shift(1)
            
        # MACD (lagged)
        df['MACD'] = (df['EMA_12'] - df['EMA_26']).shift(1)
        df['MACD_Signal'] = df['MACD'].ewm(span=9).mean().shift(1)
        df['MACD_Histogram'] = (df['MACD'] - df['MACD_Signal']).shift(1)
        
        # BOLLINGER BANDS (lagged)
        df['BB_Middle'] = df['Close'].rolling(window=20).mean().shift(1)
        bb_std = df['Close'].rolling(window=20).std().shift(1)
        df['BB_Upper'] = (df['BB_Middle'] + (bb_std * 2)).shift(1)
        df['BB_Lower'] = (df['BB_Middle'] - (bb_std * 2)).shift(1)
        df['BB_Width'] = ((df['BB_Upper'] - df['BB_Lower']) / df['BB_Middle']).shift(1)
        df['BB_Position'] = ((df['Close'] - df['BB_Lower']) / (df['BB_Upper'] - df['BB_Lower'])).shift(1)
        
        # RSI (lagged)
        delta = df['Close'].diff()
        gain = (delta.where(delta > 0, 0)).rolling(window=14).mean().shift(1)
        loss = (-delta.where(delta < 0, 0)).rolling(window=14).mean().shift(1)
        rs = gain / loss
        df['RSI'] = (100 - (100 / (1 + rs))).shift(1)
        
        # STOCHASTIC OSCILLATOR (lagged)
        low_min = df['Low'].rolling(window=14).min().shift(1)
        high_max = df['High'].rolling(window=14).max().shift(1)
        df['Stoch_K'] = (100 * ((df['Close'] - low_min) / (high_max - low_min))).shift(1)
        df['Stoch_D'] = df['Stoch_K'].rolling(window=3).mean().shift(1)
        
        # AVERAGE TRUE RANGE (ATR)
        high_low = df['High'] - df['Low']
        high_close = np.abs(df['High'] - df['Close'].shift(1))
        low_close = np.abs(df['Low'] - df['Close'].shift(1))
        true_range = np.maximum(np.maximum(high_low, high_close), low_close)
        df['ATR'] = true_range.rolling(window=14).mean().shift(1)
        
        # RATE OF CHANGE (ROC)
        for period in [5, 10, 20]:
            df[f'ROC_{period}'] = ((df['Close'] - df['Close'].shift(period)) / df['Close'].shift(period)).shift(1)
        
        # MOMENTUM
        for period in [5, 10, 20]:
            df[f'Momentum_{period}'] = (df['Close'] - df['Close'].shift(period)).shift(1)
        
        # ON-BALANCE VOLUME (OBV)
        df['OBV'] = (np.sign(df['Close'].diff()) * df['Volume']).cumsum().shift(1)
        
        # VOLATILITY FEATURES
        for window in [5, 10, 20, 30]:
            df[f'Volatility_{window}'] = df['Returns'].rolling(window=window).std().shift(1)
            
        # PRICE MOMENTUM FEATURES
        for period in [1, 3, 5, 10, 20]:
            df[f'Price_Change_{period}d'] = df['Close'].pct_change(periods=period).shift(1)
            
        # LAGGED FEATURES
        for lag in range(1, self.lookback_days + 1):
            df[f'Close_Lag_{lag}'] = df['Close'].shift(lag)
            df[f'Volume_Lag_{lag}'] = df['Volume'].shift(lag)
            df[f'Returns_Lag_{lag}'] = df['Returns'].shift(lag)
        
        # TIME-BASED FEATURES
        df['DayOfWeek'] = df.index.dayofweek
        df['Month'] = df.index.month
        df['Quarter'] = df.index.quarter
        df['IsMonthStart'] = df.index.is_month_start.astype(int)
        df['IsMonthEnd'] = df.index.is_month_end.astype(int)
        
        # Define target as NEXT DAY's closing price
        print("üéØ Setting target as next day's closing price...")
        df['Target'] = df['Close'].shift(-1)
        
        # Drop rows with NaN values (from rolling calculations and the last row due to shift(-1))
        initial_len = len(df)
        df = df.dropna()
        final_len = len(df)
        
        print(f"üìä Data points: {initial_len} ‚Üí {final_len} (removed {initial_len - final_len} NaN rows)")
        print(f"üéØ Target variable: 'Close' shifted by -1 (predicting tomorrow's price)")
        
        # Select feature columns (excluding target and raw price columns)
        exclude_cols = ['Close', 'Open', 'High', 'Low', 'Volume', 'Target', 'Dividends', 'Stock Splits']
        feature_columns = [col for col in df.columns if col not in exclude_cols]
        
        self.features = df[feature_columns]
        self.target = df['Target']  # Next day's close
        self.feature_names = feature_columns
        
        # Verify the time series structure
        self._verify_time_series_structure(df)
        
        print(f"üîß Created {len(feature_columns)} features with {len(df)} valid samples")
        print("‚úÖ Time series structure corrected - no data leakage!")
        return True
    
    def _verify_time_series_structure(self, df: pd.DataFrame):
        """Verify that the time series structure is correct"""
        print("\nüîç Verifying time series structure...")
        
        # Check a few sample rows to verify the structure
        sample_idx = min(5, len(df) - 1)
        for i in range(sample_idx):
            current_date = df.index[i]
            current_close = df['Close'].iloc[i]
            target_close = df['Target'].iloc[i]
            next_day_close = df['Close'].iloc[i + 1] if i + 1 < len(df) else None
            
            print(f"  üìÖ {current_date.strftime('%Y-%m-%d')}:")
            print(f"     Today's Close: ‚Çπ{current_close:.2f}")
            print(f"     Target (Tomorrow): ‚Çπ{target_close:.2f}")
            if next_day_close:
                print(f"     Actual Tomorrow: ‚Çπ{next_day_close:.2f}")
                print(f"     Match: {'‚úÖ' if abs(target_close - next_day_close) < 0.01 else '‚ùå'}")
        
        # Verify no data leakage in features
        print(f"\nüìä Feature date ranges: {df.index[0].strftime('%Y-%m-%d')} to {df.index[-2].strftime('%Y-%m-%d')}")
        print(f"üéØ Target date ranges: {df.index[1].strftime('%Y-%m-%d')} to {df.index[-1].strftime('%Y-%m-%d')}")
        print("‚úÖ Time series verification complete!")

    def hyperparameter_tuning(self, n_iter: int = 10, cv_splits: int = 3) -> Dict:
        """
        Advanced hyperparameter tuning with TimeSeriesSplit
        """
        if self.features is None or self.target is None:
            print("Features not created. Please run create_corrected_features() first.")
            return {}
        
        print(f"üéØ Starting hyperparameter tuning with {n_iter} iterations...")
        
        # Use smaller dataset for faster tuning
        split_idx = int(len(self.features) * 0.7)  # Use 70% for tuning
        X_tune = self.features[:split_idx]
        y_tune = self.target[:split_idx]
        
        # Scale features
        scaler = StandardScaler()
        X_tune_scaled = scaler.fit_transform(X_tune)
        
        # Define parameter grids for each model
        param_grids = {
            'Random Forest': {
                'n_estimators': [100, 200],
                'max_depth': [5, 10, 15],
                'min_samples_split': [2, 5],
                'min_samples_leaf': [1, 2],
                'max_features': ['sqrt', 'log2']
            },
            'XGBoost': {
                'n_estimators': [100, 200],
                'max_depth': [3, 6],
                'learning_rate': [0.01, 0.1],
                'subsample': [0.8, 0.9],
                'colsample_bytree': [0.8, 0.9]
            },
            'LightGBM': {
                'n_estimators': [100, 200],
                'max_depth': [3, 6],
                'learning_rate': [0.01, 0.1],
                'num_leaves': [31, 63],
                'subsample': [0.8, 0.9]
            }
        }
        
        best_params = {}
        tscv = TimeSeriesSplit(n_splits=min(cv_splits, split_idx//10))  # Ensure we have enough data per split
        
        for model_name in ['Random Forest', 'XGBoost', 'LightGBM']:
            print(f"\nüîß Tuning {model_name}...")
            
            if model_name == 'Random Forest':
                model = RandomForestRegressor(random_state=42, n_jobs=-1)
            elif model_name == 'XGBoost':
                model = xgb.XGBRegressor(random_state=42, verbosity=0, n_jobs=-1)
            elif model_name == 'LightGBM':
                model = lgb.LGBMRegressor(random_state=42, verbose=-1, n_jobs=-1)
            
            try:
                # Randomized search with time series cross-validation
                random_search = RandomizedSearchCV(
                    estimator=model,
                    param_distributions=param_grids[model_name],
                    n_iter=n_iter,
                    cv=tscv,
                    scoring='neg_mean_squared_error',
                    n_jobs=-1,
                    random_state=42,
                    verbose=0
                )
                
                random_search.fit(X_tune_scaled, y_tune)
                
                best_params[model_name] = random_search.best_params_
                print(f"‚úÖ Best parameters for {model_name}:")
                for param, value in random_search.best_params_.items():
                    print(f"   {param}: {value}")
                print(f"   Best CV Score: {-random_search.best_score_:.4f}")
                
            except Exception as e:
                print(f"‚ùå Error tuning {model_name}: {e}")
                print(f"‚ö†Ô∏è Using default parameters for {model_name}")
                # Set default parameters if tuning fails
                if model_name == 'Random Forest':
                    best_params[model_name] = {'n_estimators': 100, 'max_depth': 10}
                elif model_name == 'XGBoost':
                    best_params[model_name] = {'n_estimators': 100, 'max_depth': 6, 'learning_rate': 0.1}
                elif model_name == 'LightGBM':
                    best_params[model_name] = {'n_estimators': 100, 'max_depth': 6, 'learning_rate': 0.1}
        
        self.best_params = best_params
        print(f"\nüéØ Hyperparameter tuning completed!")
        return best_params

    def walk_forward_validation(self, n_splits: int = 5, use_tuned_params: bool = True) -> Dict:
        """
        Walk-forward validation with hyperparameter tuning option
        """
        if self.features is None or self.target is None:
            print("Features not created. Please run create_corrected_features() first.")
            return {}
        
        print(f"‚è≥ Starting walk-forward validation with {n_splits} splits...")
        print("üìà Using corrected time series structure (predicting next day's price)")
        
        # Initialize models with tuned parameters if available
        if use_tuned_params and self.best_params:
            print("üéØ Using tuned hyperparameters...")
            models = {
                'Linear Regression': LinearRegression(),
                'Random Forest': RandomForestRegressor(**self.best_params['Random Forest'], random_state=42, n_jobs=-1),
                'XGBoost': xgb.XGBRegressor(**self.best_params['XGBoost'], random_state=42, verbosity=0, n_jobs=-1),
                'LightGBM': lgb.LGBMRegressor(**self.best_params['LightGBM'], random_state=42, verbose=-1, n_jobs=-1)
            }
        else:
            print("‚öôÔ∏è Using default parameters...")
            models = {
                'Linear Regression': LinearRegression(),
                'Random Forest': RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1),
                'XGBoost': xgb.XGBRegressor(n_estimators=100, random_state=42, verbosity=0, n_jobs=-1),
                'LightGBM': lgb.LGBMRegressor(n_estimators=100, random_state=42, verbose=-1, n_jobs=-1)
            }
        
        # Time series cross-validation
        tscv = TimeSeriesSplit(n_splits=min(n_splits, len(self.features)//50))  # Ensure reasonable splits
        
        # Enhanced results storage
        cv_results = {name: {
            'rmse': [], 'mae': [], 'r2': [], 'mape': [], 'smape': [], 
            'predictions': [], 'actuals': [], 'dates': []
        } for name in models.keys()}
        
        fold = 1
        for train_idx, test_idx in tscv.split(self.features):
            print(f"üìä Processing fold {fold}/{tscv.n_splits}...")
            print(f"   Train: {self.features.index[train_idx[0]].strftime('%Y-%m-%d')} to {self.features.index[train_idx[-1]].strftime('%Y-%m-%d')}")
            print(f"   Test:  {self.features.index[test_idx[0]].strftime('%Y-%m-%d')} to {self.features.index[test_idx[-1]].strftime('%Y-%m-%d')}")
            
            # Split data
            X_train, X_test = self.features.iloc[train_idx], self.features.iloc[test_idx]
            y_train, y_test = self.target.iloc[train_idx], self.target.iloc[test_idx]
            
            # Scale features
            scaler = StandardScaler()
            X_train_scaled = scaler.fit_transform(X_train)
            X_test_scaled = scaler.transform(X_test)
            
            # Train and evaluate each model
            for name, model in models.items():
                try:
                    # Clone model for this fold
                    if name == 'Linear Regression':
                        fold_model = LinearRegression()
                    elif name == 'Random Forest':
                        fold_model = RandomForestRegressor(**model.get_params())
                    elif name == 'XGBoost':
                        fold_model = xgb.XGBRegressor(**model.get_params())
                    else:  # LightGBM
                        fold_model = lgb.LGBMRegressor(**model.get_params())
                    
                    # Train model
                    fold_model.fit(X_train_scaled, y_train)
                    
                    # Make predictions
                    y_pred = fold_model.predict(X_test_scaled)
                    
                    # Calculate enhanced metrics
                    rmse = np.sqrt(mean_squared_error(y_test, y_pred))
                    mae = mean_absolute_error(y_test, y_pred)
                    r2 = r2_score(y_test, y_pred)
                    mape = self._calculate_mape(y_test, y_pred)
                    smape = self._calculate_smape(y_test, y_pred)
                    
                    # Store results
                    cv_results[name]['rmse'].append(rmse)
                    cv_results[name]['mae'].append(mae)
                    cv_results[name]['r2'].append(r2)
                    cv_results[name]['mape'].append(mape)
                    cv_results[name]['smape'].append(smape)
                    cv_results[name]['predictions'].extend(y_pred)
                    cv_results[name]['actuals'].extend(y_test)
                    cv_results[name]['dates'].extend(y_test.index)
                    
                except Exception as e:
                    print(f"‚ùå Error in {name} fold {fold}: {e}")
                    continue
            
            fold += 1
        
        # Calculate ensemble weights based on performance
        self._calculate_ensemble_weights(cv_results)
        
        # Display enhanced results
        self._display_validation_results(cv_results)
        
        self.walk_forward_results = cv_results
        return cv_results
    
    def _calculate_mape(self, y_true: np.ndarray, y_pred: np.ndarray) -> float:
        """Calculate Mean Absolute Percentage Error"""
        with np.errstate(divide='ignore', invalid='ignore'):
            mape = np.mean(np.abs((y_true - y_pred) / y_true)) * 100
        return mape if np.isfinite(mape) else 100.0
    
    def _calculate_smape(self, y_true: np.ndarray, y_pred: np.ndarray) -> float:
        """Calculate Symmetric Mean Absolute Percentage Error"""
        denominator = (np.abs(y_true) + np.abs(y_pred))
        # Avoid division by zero
        denominator = np.where(denominator == 0, 1, denominator)
        return 100/len(y_true) * np.sum(2 * np.abs(y_pred - y_true) / denominator)
    
    def _calculate_ensemble_weights(self, cv_results: Dict):
        """Calculate ensemble weights based on model performance"""
        model_scores = {}
        
        for model_name, metrics in cv_results.items():
            if len(metrics['rmse']) > 0:  # Only if we have results
                # Use negative RMSE as score (lower RMSE is better)
                avg_rmse = np.mean(metrics['rmse'])
                if avg_rmse > 0:  # Avoid division by zero
                    model_scores[model_name] = 1 / avg_rmse  # Inverse of RMSE
        
        # Normalize weights to sum to 1
        if model_scores:
            total_score = sum(model_scores.values())
            self.ensemble_weights = {model: score/total_score for model, score in model_scores.items()}
        else:
            # Equal weights if no scores available
            model_names = list(cv_results.keys())
            self.ensemble_weights = {name: 1/len(model_names) for name in model_names}
        
        print(f"\nüéØ Ensemble Weights: {self.ensemble_weights}")
    
    def _display_validation_results(self, cv_results: Dict):
        """Display validation results with honest metrics"""
        print(f"\n{'='*80}")
        print(f"üéØ HONEST VALIDATION RESULTS (Predicting Next Day's Price)")
        print(f"{'='*80}")
        print("üìä Note: These are REALISTIC performance metrics without data leakage")
        
        best_model = None
        best_r2 = -np.inf
        
        for name, metrics in cv_results.items():
            if len(metrics['r2']) > 0:
                avg_rmse = np.mean(metrics['rmse'])
                avg_mae = np.mean(metrics['mae'])
                avg_r2 = np.mean(metrics['r2'])
                avg_mape = np.mean(metrics['mape'])
                avg_smape = np.mean(metrics['smape'])
                
                print(f"\n{name}:")
                print(f"  RMSE:  ‚Çπ{avg_rmse:.2f} ¬± {np.std(metrics['rmse']):.2f}")
                print(f"  MAE:   ‚Çπ{avg_mae:.2f} ¬± {np.std(metrics['mae']):.2f}")
                print(f"  R¬≤:    {avg_r2:.4f} ¬± {np.std(metrics['r2']):.4f}")
                print(f"  MAPE:  {avg_mape:.2f}% ¬± {np.std(metrics['mape']):.2f}")
                print(f"  SMAPE: {avg_smape:.2f}% ¬± {np.std(metrics['smape']):.2f}")
                
                if avg_r2 > best_r2:
                    best_r2 = avg_r2
                    best_model = name
        
        if best_model:
            print(f"\nüèÜ BEST MODEL: {best_model} (R¬≤ = {best_r2:.4f})")
            print(f"üí° Remember: These are HONEST metrics predicting tomorrow's price!")
            
            # Performance interpretation
            if best_r2 > 0.8:
                print("üéâ Excellent predictive power!")
            elif best_r2 > 0.6:
                print("üëç Good predictive power")
            elif best_r2 > 0.4:
                print("‚ö†Ô∏è  Moderate predictive power")
            else:
                print("üîç Limited predictive power - typical for stock price prediction")
        else:
            print("‚ùå No valid model results to display")

    def train_custom_stacking_ensemble(self, test_size: float = 0.2):
        """
        Custom stacking ensemble implementation that works with time series
        """
        if self.features is None or self.target is None:
            print("Features not created. Please run create_corrected_features() first.")
            return False
        
        print("üèóÔ∏è Training Custom Stacking Ensemble...")
        
        # Split data (preserve time order)
        split_idx = int(len(self.features) * (1 - test_size))
        X_train = self.features[:split_idx]
        X_test = self.features[split_idx:]
        y_train = self.target[:split_idx]
        y_test = self.target[split_idx:]
        
        # Scale features
        scaler = StandardScaler()
        X_train_scaled = scaler.fit_transform(X_train)
        X_test_scaled = scaler.transform(X_test)
        
        # Store test data
        self.X_test = X_test_scaled
        self.X_test_original = X_test
        self.y_test = y_test
        self.test_dates = y_test.index
        
        # Base models
        base_models = {
            'lr': LinearRegression(),
            'rf': RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1),
            'xgb': xgb.XGBRegressor(n_estimators=100, random_state=42, verbosity=0, n_jobs=-1),
            'lgb': lgb.LGBMRegressor(n_estimators=100, random_state=42, verbose=-1, n_jobs=-1)
        }
        
        # Train base models
        base_predictions_train = {}
        base_predictions_test = {}
        
        print("  üîß Training base models for stacking...")
        for name, model in base_models.items():
            try:
                model.fit(X_train_scaled, y_train)
                # Get predictions for training set (for meta-features)
                base_predictions_train[name] = model.predict(X_train_scaled)
                # Get predictions for test set
                base_predictions_test[name] = model.predict(X_test_scaled)
                print(f"    ‚úÖ {name} trained")
            except Exception as e:
                print(f"    ‚ùå Error training {name}: {e}")
        
        # Create meta-features
        if base_predictions_train:
            # Combine base model predictions into meta-features
            X_meta_train = np.column_stack(list(base_predictions_train.values()))
            X_meta_test = np.column_stack(list(base_predictions_test.values()))
            
            # Train meta-model (using Linear Regression as it's less prone to overfitting)
            meta_model = LinearRegression()
            meta_model.fit(X_meta_train, y_train)
            
            self.stacking_model = {
                'base_models': base_models,
                'meta_model': meta_model,
                'feature_names': list(base_models.keys())
            }
            
            self.meta_features = {
                'train': X_meta_train,
                'test': X_meta_test
            }
            
            print("‚úÖ Custom stacking ensemble trained successfully!")
            return True
        else:
            print("‚ùå No base models trained successfully for stacking")
            return False

    def train_all_models(self, test_size: float = 0.2, use_stacking: bool = True) -> bool:
        """Train all models with stacking ensemble option"""
        if self.features is None or self.target is None:
            print("Features not created. Please run create_corrected_features() first.")
            return False
        
        # Split data (preserve time order)
        split_idx = int(len(self.features) * (1 - test_size))
        X_train = self.features[:split_idx]
        X_test = self.features[split_idx:]
        y_train = self.target[:split_idx]
        y_test = self.target[split_idx:]
        
        print(f"üìÖ Training period: {X_train.index[0].strftime('%Y-%m-%d')} to {X_train.index[-1].strftime('%Y-%m-%d')}")
        print(f"üìÖ Testing period:  {X_test.index[0].strftime('%Y-%m-%d')} to {X_test.index[-1].strftime('%Y-%m-%d')}")
        
        # Scale features
        X_train_scaled = self.scaler.fit_transform(X_train)
        X_test_scaled = self.scaler.transform(X_test)
        
        # Store test data
        self.X_test = X_test_scaled
        self.X_test_original = X_test
        self.y_test = y_test
        self.test_dates = y_test.index
        
        print("üöÄ Training models with corrected time series structure...")
        
        # Train individual models with tuned parameters if available
        models_config = {
            'Linear Regression': LinearRegression(),
            'Random Forest': RandomForestRegressor(
                **self.best_params.get('Random Forest', {'n_estimators': 100, 'max_depth': 10}),
                random_state=42, n_jobs=-1
            ),
            'XGBoost': xgb.XGBRegressor(
                **self.best_params.get('XGBoost', {'n_estimators': 100, 'max_depth': 6, 'learning_rate': 0.1}),
                random_state=42, verbosity=0, n_jobs=-1
            ),
            'LightGBM': lgb.LGBMRegressor(
                **self.best_params.get('LightGBM', {'n_estimators': 100, 'max_depth': 6, 'learning_rate': 0.1}),
                random_state=42, verbose=-1, n_jobs=-1
            )
        }
        
        for name, model in models_config.items():
            print(f"  üîß Training {name}...")
            try:
                model.fit(X_train_scaled, y_train)
                self.models[name] = model
                print(f"    ‚úÖ {name} trained successfully")
            except Exception as e:
                print(f"    ‚ùå Error training {name}: {e}")
        
        # Train ensemble model
        self._train_ensemble_model(X_train_scaled, y_train)
        
        # Train stacking ensemble if requested
        if use_stacking:
            self.train_custom_stacking_ensemble(test_size)
        
        print("‚úÖ All models trained successfully with proper time series structure!")
        return True
    
    def _train_ensemble_model(self, X_train: np.ndarray, y_train: np.ndarray):
        """Train ensemble model using weighted average"""
        # Ensemble is a weighted combination of existing models
        self.models['Ensemble'] = 'weighted_average'

    def backtest_trading_strategy(self, initial_capital: float = 100000, 
                                buy_threshold: float = 0.3, 
                                sell_threshold: float = -0.3) -> Dict:
        """
        Backtest trading strategy based on model predictions
        """
        if not hasattr(self, 'predictions'):
            print("No predictions available. Please run evaluate_models() first.")
            return {}
        
        print(f"üí∞ Backtesting trading strategy with ‚Çπ{initial_capital:,.2f} initial capital...")
        
        # Use ensemble predictions for trading decisions
        if 'Ensemble' in self.predictions:
            predictions = self.predictions['Ensemble']
        elif 'Stacking Ensemble' in self.predictions:
            predictions = self.predictions['Stacking Ensemble']
        else:
            # Use the first available model
            available_models = list(self.predictions.keys())
            if available_models:
                predictions = self.predictions[available_models[0]]
            else:
                print("‚ùå No predictions available for backtesting")
                return {}
        
        actual_prices = self.y_test.values
        dates = self.test_dates
        
        # Initialize tracking variables
        capital = initial_capital
        position = 0  # Number of shares held
        portfolio_value = [initial_capital]
        trades = []
        in_position = False
        
        # Track buy and hold for comparison
        bh_shares = initial_capital / actual_prices[0]
        bh_values = [initial_capital]
        
        for i in range(1, len(predictions)):
            current_price = actual_prices[i]
            previous_price = actual_prices[i-1]
            
            # Calculate predicted return
            if i < len(predictions):
                predicted_price = predictions[i]
                predicted_return = (predicted_price - current_price) / current_price * 100
            else:
                predicted_return = 0
            
            # Trading logic
            if not in_position and predicted_return > buy_threshold:
                # BUY signal
                if abs(predicted_return) > 3.0:
                    position_size = capital * 0.5
                elif abs(predicted_return) > 1.5:
                    position_size = capital * 0.3
                else:
                    position_size = capital * 0.15

                if position_size > capital * 0.8:
                    position_size = capital * 0.8

                    
                shares_to_buy = position_size // current_price
                if shares_to_buy > 0:
                    cost = shares_to_buy * current_price
                    capital -= cost
                    position += shares_to_buy
                    in_position = True
                    self.current_stop_loss = current_price * 0.98
                    self.current_take_profit = current_price * 1.02
                    trades.append({
                        'date': dates[i],
                        'action': 'BUY',
                        'shares': shares_to_buy,
                        'price': current_price,
                        'reason': f'Predicted return: {predicted_return:.1f}%',
                        'stop_loss': self.current_stop_loss,
                        'take_profit': self.current_take_profit
                    })
            
            elif in_position:
                if current_price <= self.current_stop_loss:
                    capital += position * current_price
                    trades.append({
                        'date': dates[i],
                        'action': 'SELL',
                        'shares': position,
                        'price': current_price,
                        'reason': f'Stop loss triggered at {self.current_stop_loss:.2f}'
                    })
                    position = 0
                    in_position = False

                elif current_price >= self.current_take_profit:
                    capital += position * current_price
                    trades.append({
                        'date': dates[i],
                        'action': 'SELL',
                        'shares': position,
                        'price': current_price,
                        'reason': f'Take profit hit at {self.current_take_profit:.2f}'
                    })
                    position = 0
                    in_position = False

                elif predicted_return < sell_threshold:
                    capital += position * current_price
                    trades.append({
                        'date': dates[i],
                        'action': 'SELL',
                        'shares': position,
                        'price': current_price,
                        'reason': f'Predicted return: {predicted_return:.1f}%'
                    })

                    position = 0
                    in_position = False
            
            # Calculate current portfolio value
            current_value = capital + (position * current_price)
            portfolio_value.append(current_value)
            
            # Buy and hold value
            bh_values.append(bh_shares * current_price)
        
        # Close any open position at the end
        if in_position:
            capital += position * actual_prices[-1]
            trades.append({
                'date': dates[-1],
                'action': 'SELL',
                'shares': position,
                'price': actual_prices[-1],
                'reason': 'End of backtest period'
            })
            position = 0
        
        # Calculate performance metrics
        final_value = capital
        total_return = (final_value - initial_capital) / initial_capital * 100
        
        # Buy and hold metrics
        bh_final = bh_shares * actual_prices[-1]
        bh_return = (bh_final - initial_capital) / initial_capital * 100
        
        # Calculate additional metrics
        portfolio_returns = []
        if len(portfolio_value) > 1:
            portfolio_returns = np.diff(portfolio_value) / portfolio_value[:-1]
        
        bh_returns = []
        if len(bh_values) > 1:
            bh_returns = np.diff(bh_values) / bh_values[:-1]
        
        # Sharpe ratio (annualized)
        sharpe = 0
        if len(portfolio_returns) > 0 and np.std(portfolio_returns) > 0:
            sharpe = np.sqrt(252) * np.mean(portfolio_returns) / np.std(portfolio_returns)
        
        # Maximum drawdown
        peak = np.maximum.accumulate(portfolio_value)
        drawdown = (portfolio_value - peak) / peak
        max_drawdown = np.min(drawdown) * 100 if len(drawdown) > 0 else 0
        
        # Win rate (profitable trades)
        profitable_trades = 0
        total_trade_pairs = 0
        
        for i in range(1, len(trades), 2):
            if i < len(trades) and trades[i]['action'] == 'SELL' and trades[i-1]['action'] == 'BUY':
                buy_price = trades[i-1]['price']
                sell_price = trades[i]['price']
                total_trade_pairs += 1
                if sell_price > buy_price:
                    profitable_trades += 1
        
        win_rate = profitable_trades / total_trade_pairs * 100 if total_trade_pairs > 0 else 0
        
        # Compile results
        results = {
            'initial_capital': initial_capital,
            'final_value': final_value,
            'total_return': total_return,
            'total_trades': len(trades),
            'win_rate': win_rate,
            'sharpe_ratio': sharpe,
            'max_drawdown': max_drawdown,
            'buy_hold_return': bh_return,
            'excess_return': total_return - bh_return,
            'portfolio_values': portfolio_value,
            'buy_hold_values': bh_values,
            'dates': dates[:len(portfolio_value)],
            'trades': trades
        }
        
        # Display results
        self._display_backtest_results(results)
        
        self.backtest_results = results
        return results
    
    def _display_backtest_results(self, results: Dict):
        """Display backtest performance metrics"""
        print(f"\n{'='*80}")
        print("üí∞ TRADING STRATEGY BACKTEST RESULTS")
        print(f"{'='*80}")
        
        print(f"Initial Capital:     ‚Çπ{results['initial_capital']:,.2f}")
        print(f"Final Value:         ‚Çπ{results['final_value']:,.2f}")
        print(f"Total Return:        {results['total_return']:+.2f}%")
        print(f"Buy & Hold Return:   {results['buy_hold_return']:+.2f}%")
        print(f"Excess Return:       {results['excess_return']:+.2f}%")
        print(f"Total Trades:        {results['total_trades']}")
        print(f"Win Rate:            {results['win_rate']:.1f}%")
        print(f"Sharpe Ratio:        {results['sharpe_ratio']:.2f}")
        print(f"Max Drawdown:        {results['max_drawdown']:.1f}%")
        
        # Performance interpretation
        if results['excess_return'] > 5:
            print("üéâ Strategy significantly outperforms buy & hold!")
        elif results['excess_return'] > 0:
            print("‚úÖ Strategy outperforms buy & hold")
        else:
            print("‚ö†Ô∏è  Strategy underperforms buy & hold")
        
        if results['trades']:
            print(f"\nüìà Trading Activity (showing first 5 trades):")
            for trade in results['trades'][:5]:
                print(f"  {trade['date'].strftime('%Y-%m-%d')}: {trade['action']} {trade['shares']} shares at ‚Çπ{trade['price']:.2f}")

    def evaluate_models(self) -> Dict:
        """Evaluate all models with honest metrics"""
        if not self.models:
            print("No models trained. Please run train_all_models() first.")
            return {}
        
        results = {}
        predictions = {}
        
        for name, model in self.models.items():
            if name == 'Ensemble':
                # Calculate ensemble predictions
                ensemble_pred = self._get_ensemble_prediction()
                y_pred = ensemble_pred
            else:
                y_pred = model.predict(self.X_test)
            
            # Calculate enhanced metrics
            mse = mean_squared_error(self.y_test, y_pred)
            mae = mean_absolute_error(self.y_test, y_pred)
            r2 = r2_score(self.y_test, y_pred)
            mape = self._calculate_mape(self.y_test, y_pred)
            smape = self._calculate_smape(self.y_test, y_pred)
            
            results[name] = {
                'MSE': mse,
                'RMSE': np.sqrt(mse),
                'MAE': mae,
                'R¬≤': r2,
                'MAPE': mape,
                'SMAPE': smape
            }
            
            predictions[name] = y_pred
        
        # Evaluate stacking model if available
        if self.stacking_model is not None:
            try:
                # Get base model predictions
                base_preds = []
                for name, model in self.stacking_model['base_models'].items():
                    pred = model.predict(self.X_test)
                    base_preds.append(pred)
                
                # Combine predictions for meta-model
                X_meta_test = np.column_stack(base_preds)
                stacking_pred = self.stacking_model['meta_model'].predict(X_meta_test)
                
                stacking_mse = mean_squared_error(self.y_test, stacking_pred)
                stacking_mae = mean_absolute_error(self.y_test, stacking_pred)
                stacking_r2 = r2_score(self.y_test, stacking_pred)
                stacking_mape = self._calculate_mape(self.y_test, stacking_pred)
                stacking_smape = self._calculate_smape(self.y_test, stacking_pred)
                
                results['Stacking Ensemble'] = {
                    'MSE': stacking_mse,
                    'RMSE': np.sqrt(stacking_mse),
                    'MAE': stacking_mae,
                    'R¬≤': stacking_r2,
                    'MAPE': stacking_mape,
                    'SMAPE': stacking_smape
                }
                predictions['Stacking Ensemble'] = stacking_pred
                print("‚úÖ Stacking ensemble evaluated successfully!")
            except Exception as e:
                print(f"‚ùå Error evaluating stacking ensemble: {e}")
        
        # Calculate prediction intervals
        self._calculate_prediction_intervals(predictions)
        
        # Store evaluation results
        self.evaluation_results = results
        self.predictions = predictions
        
        # Display honest results
        self._display_honest_evaluation_results(results)
        
        return results
    
    def _get_ensemble_prediction(self) -> np.ndarray:
        """Get ensemble prediction using weighted average"""
        ensemble_pred = np.zeros(len(self.X_test))
        total_weight = 0
        
        for model_name, weight in self.ensemble_weights.items():
            if model_name in self.models and model_name != 'Ensemble':
                try:
                    pred = self.models[model_name].predict(self.X_test)
                    ensemble_pred += pred * weight
                    total_weight += weight
                except Exception as e:
                    print(f"‚ùå Error getting prediction from {model_name}: {e}")
        
        if total_weight > 0:
            ensemble_pred /= total_weight
        
        return ensemble_pred
    
    def _calculate_prediction_intervals(self, predictions: Dict, confidence: float = 0.95):
        """Calculate prediction intervals for uncertainty estimation"""
        for model_name, pred in predictions.items():
            try:
                errors = self.y_test - pred
                std_error = np.std(errors)
                
                # Z-score for given confidence level
                z_score = 1.96  # for 95% confidence
                
                self.prediction_intervals[model_name] = {
                    'lower': pred - z_score * std_error,
                    'upper': pred + z_score * std_error,
                    'std_error': std_error
                }
            except Exception as e:
                print(f"‚ùå Error calculating prediction intervals for {model_name}: {e}")
    
    def _display_honest_evaluation_results(self, results: Dict):
        """Display honest evaluation results"""
        print("\n" + "="*90)
        print(f"üìä HONEST EVALUATION RESULTS FOR {self.symbol}")
        print("="*90)
        print("üéØ Predicting Next Day's Closing Price - No Data Leakage")
        print("üí° These metrics reflect REAL predictive performance")
        
        # Sort by R¬≤ score
        sorted_results = sorted(results.items(), key=lambda x: x[1]['R¬≤'], reverse=True)
        
        for name, metrics in sorted_results:
            print(f"\n{name}:")
            print(f"  RMSE:  ‚Çπ{metrics['RMSE']:.2f}")
            print(f"  MAE:   ‚Çπ{metrics['MAE']:.2f}")
            print(f"  R¬≤:    {metrics['R¬≤']:.4f}")
            print(f"  MAPE:  {metrics['MAPE']:.2f}%")
            print(f"  SMAPE: {metrics['SMAPE']:.2f}%")
        
        if sorted_results:
            best_model = sorted_results[0][0]
            best_r2 = sorted_results[0][1]['R¬≤']
            
            print(f"\nüèÜ BEST PERFORMING MODEL: {best_model}")
            print(f"üìà Predictive Power: {self._interpret_r2_score(best_r2)}")
        else:
            print("‚ùå No valid results to display")
    
    def _interpret_r2_score(self, r2: float) -> str:
        """Interpret R¬≤ score for stock prediction"""
        if r2 > 0.8:
            return "üéâ Excellent (Rare in stock prediction)"
        elif r2 > 0.6:
            return "üëç Very Good"
        elif r2 > 0.4:
            return "‚úÖ Good"
        elif r2 > 0.2:
            return "‚ö†Ô∏è  Moderate (Typical for stocks)"
        elif r2 > 0:
            return "üîç Limited (Common in stock prediction)"
        else:
            return "‚ùå Poor (Worse than simple average)"

    def predict_future_price(self) -> Dict:
        """Predict tomorrow's stock price using corrected approach"""
        if not self.models:
            print("No models trained. Please run train_all_models() first.")
            return {}
        
        print(f"\n{'='*70}")
        print(f"üîÆ PREDICTING TOMORROW'S PRICE FOR {self.symbol}")
        print(f"{'='*70}")
        
        current_price = self.data['Close'].iloc[-1]
        print(f"Current Price: ‚Çπ{current_price:.2f}")
        print("üí° Predicting tomorrow's closing price...")
        print("-" * 70)
        
        # Use the most recent data for prediction
        latest_features = self.features.tail(1)
        latest_scaled = self.scaler.transform(latest_features)
        
        predictions = {}
        
        # Individual model predictions
        for name, model in self.models.items():
            if name == 'Ensemble':
                pred = self._get_ensemble_prediction_single(latest_scaled)
            else:
                pred = model.predict(latest_scaled)[0]
            
            change = ((pred - current_price) / current_price) * 100
            direction = "‚Üó" if change > 0 else "‚Üò"
            
            # Realistic signal logic for next-day prediction
            signal, reasoning = self._generate_trading_signal(change)
            
            print(f"{name:18}: ‚Çπ{pred:8.2f} ({direction} {change:+6.1f}%)")
            print(f"                   {signal} - {reasoning}")
            
            predictions[name] = {
                'price': pred,
                'change_pct': change,
                'signal': signal,
                'reasoning': reasoning
            }
        
        # Stacking ensemble prediction
        if self.stacking_model is not None:
            try:
                # Get base model predictions
                base_preds = []
                for name, model in self.stacking_model['base_models'].items():
                    pred = model.predict(latest_scaled)[0]
                    base_preds.append(pred)
                
                # Combine predictions for meta-model
                X_meta = np.array(base_preds).reshape(1, -1)
                stacking_pred = self.stacking_model['meta_model'].predict(X_meta)[0]
                
                stacking_change = ((stacking_pred - current_price) / current_price) * 100
                stacking_signal, stacking_reasoning = self._generate_trading_signal(stacking_change)
                
                print(f"{'Stacking Ensemble':18}: ‚Çπ{stacking_pred:8.2f} ({'‚Üó' if stacking_change > 0 else '‚Üò'} {stacking_change:+6.1f}%)")
                print(f"                   {stacking_signal} - {stacking_reasoning}")
                
                predictions['Stacking Ensemble'] = {
                    'price': stacking_pred,
                    'change_pct': stacking_change,
                    'signal': stacking_signal,
                    'reasoning': stacking_reasoning
                }
            except Exception as e:
                print(f"‚ùå Error getting stacking ensemble prediction: {e}")
        
        # Display ensemble recommendation
        best_pred = predictions.get('Stacking Ensemble') or predictions.get('Ensemble')
        if best_pred:
            print(f"\nüéØ ENSEMBLE RECOMMENDATION: {best_pred['signal']}")
            print(f"üìä Expected Price: ‚Çπ{best_pred['price']:.2f}")
            print(f"üìà Expected Change: {best_pred['change_pct']:+.1f}%")
            print(f"üí° Reasoning: {best_pred['reasoning']}")
        
        print(f"\n‚ö†Ô∏è  DISCLAIMER: Stock predictions are inherently uncertain.")
        print("   Use this as one of many tools for investment decisions.")
        
        return predictions
    
    def _generate_trading_signal(self, change_pct: float) -> Tuple[str, str]:
        """Generate trading signal based on predicted percentage change"""
        if change_pct > 2:
            return "üü¢ STRONG BUY", "Strong upward momentum expected"
        elif change_pct > 0.5:
            return "üü° WEAK BUY", "Slight upward movement expected"
        elif change_pct < -2:
            return "üî¥ STRONG SELL", "Strong downward pressure expected"
        elif change_pct < -0.5:
            return "üü† WEAK SELL", "Slight downward movement expected"
        else:
            return "‚ö™ HOLD", "Minimal movement expected"
    
    def _get_ensemble_prediction_single(self, features: np.ndarray) -> float:
        """Get ensemble prediction for single sample"""
        ensemble_pred = 0
        total_weight = 0
        
        for model_name, weight in self.ensemble_weights.items():
            if model_name in self.models and model_name != 'Ensemble':
                try:
                    pred = self.models[model_name].predict(features)[0]
                    ensemble_pred += pred * weight
                    total_weight += weight
                except Exception as e:
                    print(f"‚ùå Error getting prediction from {model_name}: {e}")
        
        if total_weight > 0:
            ensemble_pred /= total_weight
        
        return ensemble_pred

    def plot_enhanced_results(self, days_to_show: int = 60):
        """Create enhanced plots showing backtest results and model performance"""
        if not hasattr(self, 'predictions'):
            print("No predictions available. Please run evaluate_models() first.")
            return
        
        # Create subplots
        fig = make_subplots(
            rows=2, cols=2,
            subplot_titles=(
                'Model Predictions vs Actual (Next Day)', 
                'Backtest Performance vs Buy & Hold',
                'Model Performance Comparison', 
                'Prediction Error Distribution'
            )
        )
        
        # Plot 1: Predictions vs Actual
        recent_actual = self.y_test.iloc[-days_to_show:]
        recent_dates = self.test_dates[-days_to_show:]
        
        fig.add_trace(
            go.Scatter(x=recent_dates, y=recent_actual, name='Actual Next Day', 
                      line=dict(color='black', width=3)),
            row=1, col=1
        )
        
        colors = ['blue', 'red', 'green', 'orange', 'purple']
        model_count = 0
        for i, (name, pred) in enumerate(self.predictions.items()):
            if name in ['Ensemble', 'Stacking Ensemble']:  # Highlight ensembles
                recent_pred = pred[-days_to_show:]
                fig.add_trace(
                    go.Scatter(x=recent_dates, y=recent_pred, name=f'{name} Pred', 
                              line=dict(color=colors[model_count % len(colors)], width=2)),
                    row=1, col=1
                )
                model_count += 1
        
        # Plot 2: Backtest performance
        if hasattr(self, 'backtest_results') and self.backtest_results:
            dates = self.backtest_results['dates']
            portfolio_values = self.backtest_results['portfolio_values']
            bh_values = self.backtest_results['buy_hold_values']
            
            # Ensure we don't exceed available data
            show_count = min(days_to_show, len(dates))
            
            fig.add_trace(
                go.Scatter(x=dates[:show_count], y=portfolio_values[:show_count], name='Trading Strategy',
                          line=dict(color='green', width=3)),
                row=1, col=2
            )
            fig.add_trace(
                go.Scatter(x=dates[:show_count], y=bh_values[:show_count], name='Buy & Hold',
                          line=dict(color='blue', width=2, dash='dash')),
                row=1, col=2
            )
        
        # Plot 3: Model performance (R¬≤)
        if hasattr(self, 'evaluation_results'):
            model_names = list(self.evaluation_results.keys())
            r2_scores = [self.evaluation_results[name]['R¬≤'] for name in model_names]
            
            fig.add_trace(
                go.Bar(x=model_names, y=r2_scores, name='R¬≤ Score',
                      marker_color=colors[:len(model_names)]),
                row=2, col=1
            )
        
        # Plot 4: Error distribution
        if 'Ensemble' in self.predictions:
            errors = self.y_test - self.predictions['Ensemble']
            fig.add_trace(
                go.Histogram(x=errors, name='Prediction Errors',
                            marker_color='orange'),
                row=2, col=2
            )
        
        # Update layout
        fig.update_layout(
            title_text=f"üìä Enhanced Stock Prediction Analysis - {self.symbol}",
            title_x=0.5,
            height=800,
            showlegend=True
        )
        
        fig.update_xaxes(title_text="Date", row=1, col=1)
        fig.update_xaxes(title_text="Date", row=1, col=2)
        fig.update_xaxes(title_text="Model", row=2, col=1)
        fig.update_xaxes(title_text="Error (‚Çπ)", row=2, col=2)
        fig.update_yaxes(title_text="Price (‚Çπ)", row=1, col=1)
        fig.update_yaxes(title_text="Portfolio Value (‚Çπ)", row=1, col=2)
        fig.update_yaxes(title_text="R¬≤ Score", row=2, col=1)
        fig.update_yaxes(title_text="Frequency", row=2, col=2)
        
        fig.show()

    def create_shap_explanations(self, sample_size: int = 100):
        """Create SHAP explanations for model interpretability"""
        print("üîç Creating SHAP explanations...")
        
        # Use a sample of the data for SHAP
        sample_size = min(sample_size, len(self.X_test_original))
        sample_idx = np.random.choice(len(self.X_test_original), sample_size, replace=False)
        X_sample = self.X_test_original.iloc[sample_idx]
        X_sample_scaled = self.scaler.transform(X_sample)
        
        for name, model in self.models.items():
            if name in ['Ensemble', 'Linear Regression']:
                continue
                
            if name in ['XGBoost', 'LightGBM', 'Random Forest']:
                try:
                    # Tree-based models use TreeExplainer
                    explainer = shap.TreeExplainer(model)
                    shap_values = explainer.shap_values(X_sample_scaled)
                    
                    self.shap_explainers[name] = {
                        'explainer': explainer,
                        'shap_values': shap_values,
                        'sample_data': X_sample_scaled
                    }
                    print(f"‚úÖ SHAP explanations created for {name}")
                except Exception as e:
                    print(f"‚ùå Error creating SHAP for {name}: {e}")
        
        print("‚úÖ SHAP explanations completed!")

    def save_model(self, filepath: str) -> bool:
        """Save trained models and configuration"""
        try:
            model_data = {
                'models': self.models,
                'scaler': self.scaler,
                'feature_names': self.feature_names,
                'ensemble_weights': self.ensemble_weights,
                'best_params': self.best_params,
                'stacking_model': self.stacking_model,
                'metadata': {
                    'symbol': self.symbol,
                    'period': self.period,
                    'lookback_days': self.lookback_days,
                    'last_trained': pd.Timestamp.now()
                }
            }
            
            joblib.dump(model_data, filepath)
            print(f"‚úÖ Model saved to {filepath}")
            return True
            
        except Exception as e:
            print(f"‚ùå Error saving model: {e}")
            return False
    
    def load_model(self, filepath: str) -> bool:
        """Load pre-trained models"""
        try:
            model_data = joblib.load(filepath)
            self.models = model_data['models']
            self.scaler = model_data['scaler']
            self.feature_names = model_data['feature_names']
            self.ensemble_weights = model_data['ensemble_weights']
            self.best_params = model_data.get('best_params', {})
            self.stacking_model = model_data.get('stacking_model')
            
            print(f"‚úÖ Model loaded from {filepath}")
            return True
            
        except Exception as e:
            print(f"‚ùå Error loading model: {e}")
            return False
        
def create_enhanced_streamlit_app():
    """
    Enhanced Streamlit web application with flexible stock selection
    """
    st.set_page_config(
        page_title="Enhanced Stock Predictor",
        page_icon="üìà",
        layout="wide"
    )
    
    st.title("üöÄ Enhanced Stock Price Predictor")
    st.markdown("### üáÆüá≥ Advanced Indian Stock Market Analysis")
    
    # Sidebar for user inputs
    st.sidebar.header("üìä Stock Selection")
    
    # Enhanced stock selection with custom input
    stock_option = st.sidebar.radio(
        "Choose stock input method:",
        ["Select from popular stocks", "Enter custom symbol"]
    )
    
    if stock_option == "Select from popular stocks":
        # Expanded list of Indian stocks
        indian_stocks = {
            'TCS.NS': 'Tata Consultancy Services',
            'INFY.NS': 'Infosys', 
            'RELIANCE.NS': 'Reliance Industries',
            'HDFCBANK.NS': 'HDFC Bank',
            'ICICIBANK.NS': 'ICICI Bank',
            'SBIN.NS': 'State Bank of India',
            'KOTAKBANK.NS': 'Kotak Mahindra Bank',
            'WIPRO.NS': 'Wipro',
            'MARUTI.NS': 'Maruti Suzuki',
            'SUNPHARMA.NS': 'Sun Pharma',
            'AXISBANK.NS': 'Axis Bank',
            'BAJFINANCE.NS': 'Bajaj Finance',
            'BHARTIARTL.NS': 'Bharti Airtel',
            'HINDUNILVR.NS': 'Hindustan Unilever',
            'ITC.NS': 'ITC Limited',
            'LT.NS': 'Larsen & Toubro',
            'HCLTECH.NS': 'HCL Technologies',
            'ASIANPAINT.NS': 'Asian Paints',
            'DMART.NS': 'Avenue Supermarts',
            'TITAN.NS': 'Titan Company'
        }
        
        selected_stock = st.sidebar.selectbox(
            "Select Stock:",
            options=list(indian_stocks.keys()),
            format_func=lambda x: f"{x.replace('.NS', '')} - {indian_stocks[x]}"
        )
        
    else:
        # Option 2: Custom symbol input
        selected_stock = st.sidebar.text_input(
            "Enter Stock Symbol:",
            value="TCS.NS",
            help="Format: TCS.NS, RELIANCE.NS, INFY.NS, etc."
        ).upper()
    
    # Configuration options
    st.sidebar.header("‚öôÔ∏è Configuration")
    
    col1, col2 = st.sidebar.columns(2)
    
    with col1:
        period = st.selectbox(
            "Data Period:",
            ['1y', '2y', '3y', '5y'],
            index=3
        )
    
    with col2:
        lookback_days = st.slider("Lookback Days:", 10, 30, 20)
    
    # Enhanced options
    st.sidebar.header("üéØ Enhanced Features")
    
    run_tuning = st.sidebar.checkbox("Hyperparameter Tuning", value=True)
    run_backtest = st.sidebar.checkbox("Trading Strategy Backtest", value=True)
    use_stacking = st.sidebar.checkbox("Stacking Ensemble", value=True)
    
    if run_backtest:
        initial_capital = st.sidebar.number_input("Initial Capital (‚Çπ)", 
                                                min_value=10000, 
                                                max_value=1000000, 
                                                value=100000)
    else:
        initial_capital = 100000
    
    run_analysis = st.sidebar.button("üöÄ Run Enhanced Analysis", type="primary")
    
    # Main content
    if run_analysis:
        if not selected_stock:
            st.error("‚ùå Please select or enter a stock symbol!")
            return
            
        with st.spinner(f"üîÑ Running enhanced analysis for {selected_stock}..."):
            # Initialize predictor
            predictor = EnhancedStockPredictor(selected_stock, period, lookback_days)
            
            # Progress tracking
            progress_bar = st.progress(0)
            status_text = st.empty()
            
            try:
                # Step 1: Fetch data
                status_text.text("üìä Fetching stock data...")
                if predictor.fetch_data():
                    progress_bar.progress(10)
                    
                    # Step 2: Create features
                    status_text.text("üîß Creating corrected features...")
                    if predictor.create_corrected_features():
                        progress_bar.progress(20)
                        
                        # Step 3: Hyperparameter tuning
                        if run_tuning:
                            status_text.text("üéØ Running hyperparameter tuning...")
                            predictor.hyperparameter_tuning(n_iter=10, cv_splits=3)
                            progress_bar.progress(40)
                        
                        # Step 4: Walk-forward validation
                        status_text.text("‚è≥ Running walk-forward validation...")
                        cv_results = predictor.walk_forward_validation(n_splits=3, 
                                                                     use_tuned_params=run_tuning)
                        progress_bar.progress(50)
                        
                        # Step 5: Train models
                        status_text.text("ü§ñ Training models...")
                        if predictor.train_all_models(use_stacking=use_stacking):
                            progress_bar.progress(70)
                            
                            # Step 6: Evaluate models
                            status_text.text("üìà Evaluating models...")
                            results = predictor.evaluate_models()
                            progress_bar.progress(80)
                            
                            # Step 7: Backtest
                            if run_backtest:
                                status_text.text("üí∞ Backtesting trading strategy...")
                                backtest_results = predictor.backtest_trading_strategy(
                                    initial_capital=initial_capital
                                )
                                progress_bar.progress(90)
                            
                            # Step 8: Future prediction
                            status_text.text("üîÆ Making predictions...")
                            predictions = predictor.predict_future_price()
                            progress_bar.progress(100)
                            
                            status_text.text("‚úÖ Analysis complete!")
                            
                            # Display results
                            st.success("üéØ Enhanced analysis completed successfully!")
                            
                            # Performance metrics
                            st.subheader("üìä Model Performance (Honest Metrics)")
                            perf_data = []
                            for model, metrics in results.items():
                                perf_data.append({
                                    'Model': model,
                                    'RMSE (‚Çπ)': f"{metrics['RMSE']:.2f}",
                                    'MAE (‚Çπ)': f"{metrics['MAE']:.2f}",
                                    'R¬≤ Score': f"{metrics['R¬≤']:.4f}",
                                    'MAPE (%)': f"{metrics['MAPE']:.2f}",
                                    'SMAPE (%)': f"{metrics['SMAPE']:.2f}"
                                })
                            
                            perf_df = pd.DataFrame(perf_data)
                            st.dataframe(perf_df, use_container_width=True)
                            
                            # Backtest results
                            if run_backtest and hasattr(predictor, 'backtest_results'):
                                st.subheader("üí∞ Trading Strategy Performance")
                                
                                col1, col2, col3, col4 = st.columns(4)
                                
                                with col1:
                                    st.metric("Strategy Return", 
                                             f"{predictor.backtest_results['total_return']:.1f}%")
                                with col2:
                                    st.metric("Buy & Hold Return", 
                                             f"{predictor.backtest_results['buy_hold_return']:.1f}%")
                                with col3:
                                    st.metric("Excess Return", 
                                             f"{predictor.backtest_results['excess_return']:.1f}%")
                                with col4:
                                    st.metric("Win Rate", 
                                             f"{predictor.backtest_results['win_rate']:.1f}%")
                                
                                # Portfolio value chart
                                fig = go.Figure()
                                fig.add_trace(go.Scatter(
                                    x=predictor.backtest_results['dates'],
                                    y=predictor.backtest_results['portfolio_values'],
                                    name='Trading Strategy',
                                    line=dict(color='green', width=3)
                                ))
                                fig.add_trace(go.Scatter(
                                    x=predictor.backtest_results['dates'],
                                    y=predictor.backtest_results['buy_hold_values'],
                                    name='Buy & Hold',
                                    line=dict(color='blue', width=2, dash='dash')
                                ))
                                fig.update_layout(
                                    title="Portfolio Value Over Time",
                                    xaxis_title="Date",
                                    yaxis_title="Portfolio Value (‚Çπ)",
                                    height=400
                                )
                                st.plotly_chart(fig, use_container_width=True)
                            
                            # Future predictions
                            st.subheader("üîÆ Tomorrow's Price Prediction")
                            current_price = predictor.data['Close'].iloc[-1]
                            
                            col1, col2 = st.columns(2)
                            
                            with col1:
                                st.metric("Current Price", f"‚Çπ{current_price:.2f}")
                            
                            with col2:
                                best_pred = predictions.get('Stacking Ensemble') or predictions.get('Ensemble')
                                if best_pred:
                                    st.metric(
                                        "Best Prediction",
                                        f"‚Çπ{best_pred['price']:.2f}",
                                        delta=f"{best_pred['change_pct']:+.1f}%"
                                    )
                            
                            # All predictions table
                            pred_data = []
                            for name, pred_info in predictions.items():
                                pred_data.append({
                                    'Model': name,
                                    'Predicted Price': f"‚Çπ{pred_info['price']:.2f}",
                                    'Change %': f"{pred_info['change_pct']:+.2f}%",
                                    'Signal': pred_info['signal'],
                                    'Reasoning': pred_info['reasoning']
                                })
                            
                            pred_df = pd.DataFrame(pred_data)
                            st.dataframe(pred_df, use_container_width=True)
                            
                            # Best parameters from tuning
                            if run_tuning and predictor.best_params:
                                st.subheader("üéØ Best Hyperparameters")
                                for model_name, params in predictor.best_params.items():
                                    with st.expander(f"{model_name} Parameters"):
                                        st.json(params)
                            else:
                                st.error("Failed to train models")
                    else:
                        st.error("Failed to create features")
                else:
                    st.error("Failed to fetch data")
                    
            except Exception as e:
                st.error(f"Error during analysis: {str(e)}")
                st.exception(e)
            
            # Clear progress indicators
            progress_bar.empty()
            status_text.empty()
    
    else:
        st.info("üëÜ Configure your analysis and click 'Run Enhanced Analysis' to get started!")
        
        # Display new features
        st.subheader("‚ú® Enhanced Features:")
        
        col1, col2, col3 = st.columns(3)
        
        with col1:
            st.markdown("""
            **üéØ Hyperparameter Tuning:**
            - RandomizedSearchCV with TimeSeriesSplit
            - Optimized parameters for each model
            - Better performance with tuned settings
            - Automatic parameter selection
            """)
        
        with col2:
            st.markdown("""
            **üí∞ Trading Strategy Backtest:**
            - Real portfolio simulation
            - Buy/sell signals based on predictions
            - Performance vs buy & hold comparison
            - Sharpe ratio and max drawdown
            """)
        
        with col3:
            st.markdown("""
            **üóÉÔ∏è Stacking Ensemble:**
            - Meta-model learns to combine predictions
            - Better than simple weighted average
            - Reduced individual model bias
            - Enhanced prediction accuracy
            """)
        
        # Stock symbol examples
        st.subheader("üìã Popular Indian Stock Symbols:")
        example_stocks = {
            "Large Cap": ["RELIANCE.NS", "TCS.NS", "HDFCBANK.NS", "INFY.NS", "HINDUNILVR.NS"],
            "Mid Cap": ["BAJFINANCE.NS", "TITAN.NS", "ADANIPORTS.NS", "DMART.NS", "MARUTI.NS"],
            "Banking": ["SBIN.NS", "ICICIBANK.NS", "KOTAKBANK.NS", "AXISBANK.NS", "HDFCBANK.NS"],
            "IT": ["TCS.NS", "INFY.NS", "WIPRO.NS", "HCLTECH.NS", "TECHM.NS"]
        }
        
        for category, stocks in example_stocks.items():
            with st.expander(f"{category} Stocks"):
                cols = st.columns(4)
                for i, stock in enumerate(stocks):
                    cols[i % 4].code(stock)

def run_complete_analysis(symbol: str = "TCS.NS", period: str = "5y", run_tuning: bool = True):
    """
    Run complete analysis with all enhancements
    """
    print("üöÄ ENHANCED STOCK PREDICTION ANALYSIS")
    print("="*80)
    print(f"üìä Symbol: {symbol}")
    print(f"üìÖ Period: {period}")
    print(f"üéØ Features: Hyperparameter Tuning, Backtesting, Stacking Ensemble")
    print("="*80)
    
    # Initialize predictor
    predictor = EnhancedStockPredictor(symbol, period)
    
    try:
        # Step 1: Fetch data
        print("\n1. üìä Fetching data...")
        if not predictor.fetch_data():
            return
        
        # Step 2: Create features
        print("\n2. üîß Creating corrected features...")
        if not predictor.create_corrected_features():
            return
        
        # Step 3: Hyperparameter tuning (optional)
        if run_tuning:
            print("\n3. üéØ Hyperparameter tuning...")
            predictor.hyperparameter_tuning(n_iter=10, cv_splits=3)
        else:
            print("\n3. ‚öôÔ∏è Using default parameters...")
        
        # Step 4: Walk-forward validation
        print("\n4. ‚è≥ Walk-forward validation...")
        predictor.walk_forward_validation(n_splits=5, use_tuned_params=run_tuning)
        
        # Step 5: Train models with stacking
        print("\n5. ü§ñ Training models with stacking ensemble...")
        predictor.train_all_models(use_stacking=True)
        
        # Step 6: Evaluate models
        print("\n6. üìà Evaluating models...")
        predictor.evaluate_models()
        
        # Step 7: Backtest trading strategy
        print("\n7. üí∞ Backtesting trading strategy...")
        predictor.backtest_trading_strategy(initial_capital=100000, buy_threshold=0.3,sell_threshold=-0.3)
        
        # Step 8: Future prediction
        print("\n8. üîÆ Predicting tomorrow's price...")
        predictor.predict_future_price()
        
        # Step 9: Create explanations
        print("\n9. üîç Creating model explanations...")
        predictor.create_shap_explanations(sample_size=50)
        
        # Step 10: Plot results
        print("\n10. üìä Plotting results...")
        predictor.plot_enhanced_results()
        
        print("\n" + "="*80)
        print("üéâ ENHANCED ANALYSIS COMPLETE!")
        print("="*80)
        print("‚úÖ Hyperparameter tuning completed")
        print("‚úÖ Trading strategy backtested") 
        print("‚úÖ Stacking ensemble trained")
        print("‚úÖ All models evaluated with honest metrics")
        print("‚úÖ Tomorrow's price predicted")
        print("="*80)
        
    except Exception as e:
        print(f"\n‚ùå Error in analysis: {e}")
        import traceback
        traceback.print_exc()

def interactive_console_mode():
    """
    Interactive console mode for stock selection
    """
    print("\nüöÄ INTERACTIVE STOCK PREDICTION SYSTEM")
    print("="*50)
    
    # Stock selection
    print("\nüìä Available Stock Categories:")
    print("1. Large Cap Stocks")
    print("2. Mid Cap Stocks") 
    print("3. Banking Stocks")
    print("4. IT Stocks")
    print("5. Custom Symbol")
    
    category_choice = input("\nSelect category (1-5): ").strip()
    
    stock_categories = {
        '1': {
            'RELIANCE.NS': 'Reliance Industries',
            'TCS.NS': 'Tata Consultancy Services',
            'HDFCBANK.NS': 'HDFC Bank',
            'INFY.NS': 'Infosys',
            'HINDUNILVR.NS': 'Hindustan Unilever'
        },
        '2': {
            'BAJFINANCE.NS': 'Bajaj Finance',
            'TITAN.NS': 'Titan Company',
            'ADANIPORTS.NS': 'Adani Ports',
            'DMART.NS': 'Avenue Supermarts',
            'MARUTI.NS': 'Maruti Suzuki'
        },
        '3': {
            'SBIN.NS': 'State Bank of India',
            'ICICIBANK.NS': 'ICICI Bank',
            'KOTAKBANK.NS': 'Kotak Mahindra Bank',
            'AXISBANK.NS': 'Axis Bank',
            'HDFCBANK.NS': 'HDFC Bank'
        },
        '4': {
            'TCS.NS': 'Tata Consultancy Services',
            'INFY.NS': 'Infosys',
            'WIPRO.NS': 'Wipro',
            'HCLTECH.NS': 'HCL Technologies',
            'TECHM.NS': 'Tech Mahindra'
        }
    }
    
    selected_stock = None
    
    if category_choice in stock_categories:
        print(f"\nüìà Available Stocks in this category:")
        stocks = stock_categories[category_choice]
        for i, (symbol, name) in enumerate(stocks.items(), 1):
            print(f"{i}. {symbol} - {name}")
        
        stock_choice = input(f"\nSelect stock (1-{len(stocks)}): ").strip()
        if stock_choice.isdigit() and 1 <= int(stock_choice) <= len(stocks):
            selected_stock = list(stocks.keys())[int(stock_choice) - 1]
    
    elif category_choice == '5':
        selected_stock = input("\nEnter custom stock symbol (e.g., TCS.NS): ").strip().upper()
        if not selected_stock:
            selected_stock = "TCS.NS"
    
    else:
        print("‚ùå Invalid choice. Using default: TCS.NS")
        selected_stock = "TCS.NS"
    
    # Period selection
    print("\nüìÖ Select Data Period:")
    print("1. 1 Year")
    print("2. 2 Years") 
    print("3. 3 Years")
    print("4. 5 Years (Recommended)")
    
    period_choice = input("Select period (1-4): ").strip()
    period_map = {'1': '1y', '2': '2y', '3': '3y', '4': '5y'}
    period = period_map.get(period_choice, '5y')
    
    # Feature options
    print("\nüéØ Select Features:")
    run_tuning = input("Run hyperparameter tuning? (y/n): ").strip().lower() == 'y'
    run_backtest = input("Run trading strategy backtest? (y/n): ").strip().lower() == 'y'
    
    print(f"\nüéØ Starting analysis for {selected_stock}...")
    run_complete_analysis(
        symbol=selected_stock,
        period=period,
        run_tuning=run_tuning
    )

# Run the analysis
if __name__ == "__main__":
    import sys
    
    if len(sys.argv) > 1 and sys.argv[1] == "streamlit":
        # Run Streamlit app
        create_enhanced_streamlit_app()
    elif len(sys.argv) > 1 and sys.argv[1] == "interactive":
        # Run interactive console mode
        interactive_console_mode()
    else:
        # Run with command line arguments or default
        if len(sys.argv) > 2:
            # Command line: python script.py SYMBOL PERIOD
            symbol = sys.argv[1]
            period = sys.argv[2] if len(sys.argv) > 2 else "5y"
            run_tuning = True
        else:
            # Default run
            symbol = "TCS.NS"
            period = "5y" 
            run_tuning = True
            
        print("üöÄ ENHANCED STOCK PREDICTION SYSTEM")
        print("="*100)
        print("üéØ Now featuring: Hyperparameter Tuning + Trading Strategy Backtest + Stacking Ensemble")
        print()
        print("üí° Usage options:")
        print("   python main.py streamlit                    # Run Streamlit web app")
        print("   python main.py interactive                  # Run interactive console mode") 
        print("   python main.py RELIANCE.NS 5y              # Run for specific stock")
        print()
        
        if len(sys.argv) == 1:  # No arguments
            response = input("Run default analysis for TCS.NS? (y/n): ").strip().lower()
            if response == 'y':
                # Run complete analysis
                run_complete_analysis(symbol=symbol, period=period, run_tuning=run_tuning)
            else:
                print("Exiting. Use one of the options above.")
        else:
            # Run with provided arguments
            run_complete_analysis(symbol=symbol, period=period, run_tuning=run_tuning)
        
        print("\n" + "="*100)
        print("üéâ ALL ENHANCEMENTS SUCCESSFULLY IMPLEMENTED!")
        print("="*100)
        print("‚úÖ Flexible Stock Selection: Choose from popular stocks or enter any symbol")
        print("‚úÖ Hyperparameter Tuning: Models now optimized for maximum performance")
        print("‚úÖ Trading Strategy Backtest: Real portfolio simulation with performance metrics") 
        print("‚úÖ Stacking Ensemble: Advanced meta-model for better predictions")
        print("‚úÖ Enhanced Streamlit App: Complete web interface with all new features")
        print("‚úÖ Interactive Console Mode: User-friendly command line interface")
        print()
        print("üöÄ USAGE OPTIONS:")
        print("   Streamlit Web App:    streamlit run main.py streamlit")
        print("   Interactive Console:  python main.py interactive")
        print("   Specific Stock:       python main.py RELIANCE.NS 5y")
        print()
        print("="*100)
        print("üèÜ This is now an ENTERPRISE-GRADE stock prediction system!")
        print("üìä Professional-grade backtesting and optimization")
        print("üîç State-of-the-art ensemble methods")
        print("üåê Complete web interface for easy use")
        print("üíª Multiple usage modes for different preferences")
        print("="*100)
